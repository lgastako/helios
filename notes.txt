Helios
======

Introduction
------------

Helios is a set of client/server tools for recording arbitrary
information about events(?) that occur in software systems.  It's like
syslog but more structure or like SNMP but more flexible and not as
stupid.

It consists of several components that work together:

- Client libraries.  (Prototyped in python).  The client libraries
  allow developers to make calls to record whatever it is that they
  want to record.

- Remote queue servers.  Optional components that help scale the data
  collection on the remote nodes.

- Centralized data store.  This is where all data ultimately ends up.
  While talked about as a singluar entity in most production
  deployments would probably be a large cluster of mongo db instances.

- Report server.  This is a webapp that makes information from the
  datastore available for ad-hoc queries to consumers.  Basically
  provides a pretty/easy UI on top of the mongo query facilities.


Design Decisions
----------------

NOTE: These are all in a state of flux and may change at any moment.

- The client should use only HTTP to communicate with the server,
  including sending the actual log messages.  This means that various
  cross-cutting concerns like security and load balancing can be
  off-loaded to systems optimized for handling these concerns.

  - The obvious corollary to this is that the HTTP communication
    should be optimized using e.g. Keep-Alives and/or HTTP pipelining.
    Of course the spec says that pipelining should not be used for non
    idempotent requests like POSTs and our API should be POST oriented
    so that there is no restriction on payload size.  It may or may
    not also be a good idea to keep multiple connections per client
    open.

    - The obvious corollary to this is that the server should respond
      with a success or error message ASAP (and e.g. do queueing on
      the server side as well) so that the server is not responsible
      for causing a backup on the client side.  Of course if we're
      trying to be as fault tolerant as possible and prevent data loss
      as much as possible then we should be committing the events to
      some sort of persistent (think f-sync'd) store on the server
      side before acknowledging.

    - Another corrollary here is that since the server is going to
      already be handling an extremely high number of persistent
      connections (due to e.g. lots of apps writing lots of stuff) if
      we're adding on top of that possibly multiple http connections
      then the server will have to be extremely efficient about
      handling connections which means it should probably be
      event-driven (e.g. twisted, tornado, etc).


Open Questions
--------------

- Compression (gzip or otherwise) between client and server?

- ZeroMQ on the client side?  On the server side?

- UDP?


Client API
----------

API calls MUST return immediately.

 - Suggested implementation: Put on an in-process queue.  A
   thread/process/etc picks up the message from the in-process queue
   and depending on configuration either writes it to an
   out-of-process queue or sends it directly to the remote recorder
   server thing.

API calls MUST never raise an exception.

API calls MUST log using the default logging mechanism if they fail to
handle a document.  The logged message MUST contain the entire
document.  [Caveat: if it's under a certain size?... maybe SHOULD for
this case and/or any other case where something about the document
makes it un loggable]

In theory client APIs should provide the ability to send stuff to
different helios servers, but really that kinda goes against the point
of it, so for now, no.

... Should we have priorities or does that just complicate things?

... Should we send current timestamp and let the server do adjustments or what?


Other junk
----------
http://www.mongodb.org/display/DOCS/Using+a+Large+Number+of+Collections

That page says there's a cap of 24k namespaces and each collection
counts as a namespace as does each index so if there's one index per
collection thats a max of 12k collections, less if you have more
indexes.

Though it does say there's an --nssize option to adjust.  Max size for
namespace file is 2gb but it doesn't say how many ns's that'd
accomodate.

Maybe we should just put all events in one collection with a key that
is the type instead of making a collection per type.

Or, do something even more awesome.
